{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rateria/miniconda3/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.join(\"..\", os.getcwd()))\n",
    "\n",
    "import hydra\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from omegaconf import DictConfig\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from src.dataset import CSVDataset\n",
    "from src.multihead_attn import TransformerEncoder\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from src.utils import remove_duplicate_strings\n",
    "\n",
    "# device = \"mps\" if torch.backends.mps.is_available() else \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bi_encoder_model_name = \"pritamdeka/PubMedBERT-mnli-snli-scinli-stsb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Retriever(nn.Module):\n",
    "    \"\"\"Given a list of evidences and a claim, this returns the top-k evidences\"\"\"\n",
    "    def __init__(self, cfg: DictConfig,train_evidences=[], val_evidences=[], test_evidences=[]):\n",
    "        super().__init__()\n",
    "        self.bi_encoder = SentenceTransformer(cfg.bi_encoder_model_name, cache_folder=\"../cache\")\n",
    "        # self.bi_encoder.eval()\n",
    "        self.bi_encoder.requires_grad_(False)\n",
    "        self.k = cfg.k\n",
    "        self.data = pd.read_csv(cfg.csv_file)\n",
    "        self.train_evidence_pool = train_evidences\n",
    "        self.train_evidence_embeddings = self.bi_encoder.encode(train_evidences, convert_to_tensor=True)\n",
    "        self.val_evidence_pool = val_evidences\n",
    "        self.val_evidence_embeddings = self.bi_encoder.encode(val_evidences, convert_to_tensor=True)\n",
    "        self.test_evidence_pool = test_evidences\n",
    "        self.test_evidence_embeddings = self.bi_encoder.encode(test_evidences, convert_to_tensor=True)\n",
    "    def tokenize_and_embed(self, data):\n",
    "        # data -> [b]\n",
    "        return self.bi_encoder.encode([data], convert_to_tensor=True)\n",
    "    \n",
    "    def set_encoder_training(self, mode):\n",
    "        self.bi_encoder.train(mode)\n",
    "    \n",
    "    def forward(self, x, mode=\"train\"):\n",
    "        # x -> b, claims\n",
    "        x = self.bi_encoder.encode(x, convert_to_tensor=True)\n",
    "        # scores -> b, num_evidences, each row is the cosine similarity b/w the claim\n",
    "        # and all the evidences\n",
    "        if mode == \"train\":\n",
    "            self.evidence_embeddings = self.train_evidence_embeddings\n",
    "            self.evidence_pool = self.train_evidence_pool\n",
    "        elif mode == \"val\":\n",
    "            self.evidence_embeddings = self.val_evidence_embeddings\n",
    "            self.evidence_pool = self.val_evidence_pool\n",
    "        elif mode == \"test\":\n",
    "            self.evidence_embeddings = self.test_evidence_embeddings\n",
    "            self.evidence_pool = self.test_evidence_pool\n",
    "        cos_sim = torch.mm(x, self.evidence_embeddings.T)\n",
    "        scores, indices = torch.topk(cos_sim, self.k, dim=1)\n",
    "        evidences = [[self.evidence_pool[i] for i in row] for row in indices]\n",
    "        return scores, indices, evidences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ranker(nn.Module):\n",
    "    def __init__(self, cfg: DictConfig):\n",
    "        super().__init__()\n",
    "        # self.cross_encoder = AutoModelForSequenceClassification.from_pretrained(cfg.cross_encoder_model_name, cache_dir=\"../cache\")\n",
    "        self.cross_encoder = SentenceTransformer(cfg.bi_encoder_model_name, cache_folder=\"../cache\", device=\"cpu\")\n",
    "        self.cross_encoder.train(True)\n",
    "        # self.cross_encoder.classifier = nn.Identity()  # remove the last classifier layer\n",
    "        # self.tokenizer = AutoTokenizer.from_pretrained(cfg.cross_encoder_model_name)\n",
    "        hidden_size = 768\n",
    "        self.scorer = nn.Linear(hidden_size, 1)\n",
    "        \n",
    "    def forward(self, x, evidence_pool):\n",
    "        # x -> b, claim\n",
    "        # evidence_pool -> list of evidence strings\n",
    "        # create claim embedding pair\n",
    "        embeddings = []\n",
    "        for i, claim in enumerate(x):\n",
    "            evidences = evidence_pool[i]\n",
    "            claim_pairs = [f\"[CLS] {claim} [SEP] {evidence} [SEP]\" for evidence in evidences]\n",
    "            encoded = self.cross_encoder.encode(claim_pairs, convert_to_tensor=True)\n",
    "            embeddings.append(encoded)\n",
    "        # Convert list of tensors to a single tensor\n",
    "        embeddings_tensor = torch.stack(embeddings)\n",
    "        # print(f\"{type(embeddings_tensor)}\")\n",
    "        return embeddings_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self, input_dim, out_classes=3):\n",
    "        super().__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, out_classes)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = torch.mean(x, dim=1)\n",
    "        print(f\"classifier after mean {x.shape}\")\n",
    "        x = self.mlp(x)\n",
    "        # print(\"classifier\", x, x.shape)\n",
    "        return x, F.softmax(x, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from omegaconf import OmegaConf\n",
    "cfg = OmegaConf.load(\"./config/config.yaml\")\n",
    "\n",
    "train_dataset = CSVDataset(file_path=\"/Users/rateria/Code/cs-5787-final-project/data/csv/train.csv\")\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=cfg.batch_size, shuffle=True)\n",
    "\n",
    "val_dataset = CSVDataset(file_path=\"/Users/rateria/Code/cs-5787-final-project/data/csv/val.csv\")\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=cfg.batch_size, shuffle=False)\n",
    "\n",
    "test_dataset = CSVDataset(file_path=\"/Users/rateria/Code/cs-5787-final-project/data/csv/test.csv\")\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=cfg.batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = Retriever(cfg, train_evidences=train_dataset.get_evidences(), val_evidences=val_dataset.get_evidences(), test_evidences=test_dataset.get_evidences())\n",
    "ranker = Ranker(cfg)\n",
    "attn = TransformerEncoder(num_layers=4, input_dim=768, num_heads=1, dim_feedforward=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Classifier(768)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Nateglinide is particularly effective for controlling postprandial hyperglycemia due to its short duration of action.', 'While screening tests like CH50 and AH50 are used to evaluate complement function, their effectiveness in predicting clinical outcomes may vary.', 'The combination of Lansoprazole, Amoxicillin, and Clarithromycin is an effective treatment for Helicobacter pylori infections and related duodenal ulcers.', 'The vaccine plays a crucial role in public health efforts to control infectious diseases.', 'Awareness of tinea nigra is crucial for proper management and treatment of the condition.', 'Diagnosis of acute pericarditis typically involves analyzing ECG changes and performing echocardiography.', 'While accurate diagnosis might help some patients, it is unclear how much it influences overall mental health outcomes.', 'The management of asthma during pregnancy does not require careful consideration of pharmacological interventions.', 'Patient history is not a reliable method for diagnosing food allergies.', 'Incontinentia pigmenti is a rare genetic skin disorder predominantly seen in females, resulting from mutations in the IKBKG gene.', 'Magnesium hydroxide is excreted unchanged in urine, highlighting the importance of monitoring renal function.', 'Patients with idiopathic restrictive cardiomyopathy typically experience a good prognosis and do not require advanced therapies like heart transplantation.', 'Though mild irritation and blurred vision are common, the severity of side effects may differ among patients.', 'Surgeons and anesthesiologists always agree on the need for transfusion based on hemoglobin levels alone, eliminating the need for communication.', 'While advanced imaging is important for identifying complications, its effectiveness may vary based on the type of complication and timing of the intervention.', 'The effectiveness of guaifenesin in chronic bronchitis is debated, suggesting that some individuals may benefit while others may not.', 'The combination of Guaifenesin and Codeine is frequently prescribed to treat coughs arising from colds and flu.', 'While sclerosing agents may help in preventing recurrence, their effectiveness can depend on individual patient responses.', 'Healthcare providers must monitor patients for potential adverse effects associated with Colesevelam, such as pancreatitis.', 'Caution is recommended when using these medications in young children.', 'While continuous positive airway pressure (CPAP) therapy is recommended for patients already using it, its effectiveness in improving postoperative recovery for all OSA patients is not definitively established.', 'Econazole can be safely used by anyone without concerns for allergic reactions or side effects.', 'Although the system aims to improve patient outcomes, the actual benefits may depend on various external factors beyond staging.', 'The increased incidence of heart failure in patients with pre-existing conditions suggests that Bezlotoxumab may pose risks that are not fully understood.', 'Extensive clinical trials have shown that doxylamine and pyridoxine pose no significant teratogenic risks, making them safe for use during pregnancy.', 'The execution of PCI has no impact on mortality rates for patients with acute STEMI.', 'Routine use of pulmonary artery catheterization has been proven beneficial for all critically ill patients, regardless of their specific conditions.', 'Although Theophylline has some anti-inflammatory effects, its overall efficacy compared to newer treatments remains unclear.', 'Certain treatments for perioral dermatitis might work for some patients but could lead to flare-ups in others, leaving the effectiveness of treatments uncertain.', 'Common side effects of Cromolyn include headache and gastrointestinal issues.', 'It is recommended that patients apply the treatment as frequently as possible from the start for immediate results.', 'Although the vaccine is administered as two tablets, it is unclear if this method is the most effective delivery system for all individuals.', 'The ointment is recommended for application twice daily to effectively manage plaque psoriasis.', 'Individualized treatment plans could either improve the quality of life for heart failure patients or complicate their management, depending on various factors.', \"The treatment of advanced AIDS-related Kaposi sarcoma includes both systemic treatments and local therapies, but it's unclear how effective these combinations are in improving outcomes.\", 'The effectiveness of Cognitive Behavioral Therapy in managing pain may vary among individuals, leading to mixed experiences in pain reduction.', 'Isoconazole is primarily administered systemically rather than locally for treating fungal infections.', 'The Global Initiative for Asthma (GINA) guidelines support the use of spirometry to confirm asthma diagnosis and assess airflow obstruction severity.', 'MCC does not require a multidisciplinary approach for treatment, as surgical excision alone is sufficient for all stages of the disease.', 'Understanding the pathophysiology of elevated ICP is essential for effective treatment and improved patient outcomes.', 'The once-daily application of Luliconazole improves patient adherence to treatment regimens.', 'The dosing of Amitriptyline and Perphenazine may vary, but it is unclear how individual responses affect the overall treatment protocol.', 'Structured surveillance post-treatment is essential for managing new lesions and monitoring recurrence.', 'Ofatumumab is an effective treatment for chronic lymphocytic leukemia, especially in patients who have undergone previous therapies.', \"Nitrendipine's once-daily dosing makes it a convenient option for hypertension management.\", 'GERD has no impact on the severity of asthma symptoms or the response to treatment.', \"While direct-acting antivirals have changed HCV treatment, the extent of their effectiveness may vary depending on patients' adherence and co-existing conditions.\", 'Supportive care is sufficient on its own to manage the symptoms of ADA deficiency without the need for more advanced therapies.', 'There are indications that while Apadaz™ is effective for some, its use in patients with a history of substance use disorders may yield unpredictable outcomes.', 'While some patients with congenital long QT syndrome experience syncope, others may not show any symptoms despite having prolonged QT intervals.'), tensor([0, 2, 0, 0, 0, 0, 2, 1, 1, 0, 0, 1, 2, 1, 2, 2, 0, 2, 0, 0, 2, 1, 2, 2,\n",
      "        0, 1, 1, 2, 2, 0, 1, 2, 0, 2, 2, 2, 1, 0, 1, 0, 0, 2, 0, 0, 0, 1, 2, 1,\n",
      "        2, 2])]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Tensor for argument #1 'mat1' is on CPU, but expected it to be on GPU (while checking arguments for mm)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m x, y \u001b[38;5;241m=\u001b[39m batch\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# rav = RAV()\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# print(rav)\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m scores, indices, evidences \u001b[38;5;241m=\u001b[39m \u001b[43mretriever\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(scores\u001b[38;5;241m.\u001b[39mshape, indices\u001b[38;5;241m.\u001b[39mshape, \u001b[38;5;28mlen\u001b[39m(evidences))\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# print(f\"\\n{evidences}\\n\")\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# print(\"initial device\", x.device)\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[3], line 37\u001b[0m, in \u001b[0;36mRetriever.forward\u001b[0;34m(self, x, mode)\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevidence_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_evidence_embeddings\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevidence_pool \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_evidence_pool\n\u001b[0;32m---> 37\u001b[0m cos_sim \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevidence_embeddings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m scores, indices \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtopk(cos_sim, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     39\u001b[0m evidences \u001b[38;5;241m=\u001b[39m [[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevidence_pool[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m row] \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m indices]\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Tensor for argument #1 'mat1' is on CPU, but expected it to be on GPU (while checking arguments for mm)"
     ]
    }
   ],
   "source": [
    "for batch in train_dataloader:\n",
    "    print(batch)\n",
    "    x, y = batch\n",
    "    # rav = RAV()\n",
    "    # print(rav)\n",
    "    scores, indices, evidences = retriever(x)\n",
    "    print(scores.shape, indices.shape, len(evidences))\n",
    "    # print(f\"\\n{evidences}\\n\")\n",
    "    # print(\"initial device\", x.device)\n",
    "    h = ranker(x, evidences)\n",
    "    h = h.to(\"cpu\")\n",
    "    print(h.shape, h.device)\n",
    "    enc_out = attn(h)\n",
    "    print(enc_out.shape)\n",
    "    logits, out = classifier(enc_out)\n",
    "    print(out, out.shape)\n",
    "    loss = nn.CrossEntropyLoss()(logits, y)\n",
    "    print(f\"loss: {loss}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class MyLightningModule(pl.LightningModule):\n",
    "    def __init__(self, retriever, ranker, attn, classifier, learning_rate=1e-3):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            retriever: Module for retrieving evidence.\n",
    "            ranker: Module for ranking evidence.\n",
    "            attn: Attention module.\n",
    "            classifier: Classification module.\n",
    "            learning_rate: Learning rate for the optimizer.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.retriever = retriever\n",
    "        self.ranker = ranker\n",
    "        self.attn = attn\n",
    "        self.classifier = classifier\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        # Freeze the retriever\n",
    "        for param in self.retriever.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        self.retriever.eval()\n",
    "        \n",
    "        for param in self.ranker.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        self.ranker.eval()\n",
    "        \n",
    "        self.save_hyperparameters()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward pass to process the input\n",
    "        scores, indices, evidences = self.retriever(x)\n",
    "        h = self.ranker(x, evidences)\n",
    "        enc_out = self.attn(h)\n",
    "        out = self.classifier(enc_out)\n",
    "        return out\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # Single training step\n",
    "        x, y = batch\n",
    "        scores, indices, evidences = self.retriever(x, mode=\"train\")\n",
    "        h = self.ranker(x, evidences)\n",
    "        enc_out = self.attn(h)\n",
    "        logits, out = self.classifier(enc_out)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = self.loss_fn(logits, y)\n",
    "        print(f\"loss: {loss}\")\n",
    "        self.log(\"train_loss\", loss)  # Log the loss for monitoring\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        # Optimizer configuration\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        # Validation step (optional, similar to training_step)\n",
    "        x, y = batch\n",
    "        scores, indices, evidences = self.retriever(x, mode=\"val\")\n",
    "        h = self.ranker(x, evidences)\n",
    "        enc_out = self.attn(h)\n",
    "        logits, out = self.classifier(enc_out)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = self.loss_fn(logits, y)\n",
    "        self.log(\"val_loss\", loss)  # Log the validation loss\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retriever = Retriever(cfg)\n",
    "# ranker = Ranker(cfg)\n",
    "# attn = TransformerEncoder(num_layers=4, input_dim=768, num_heads=1, dim_feedforward=128)\n",
    "# classifier = Classifier(768)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msr2369\u001b[0m (\u001b[33msr2369-cornell-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/rateria/Code/cs-5787-final-project/wandb/run-20241207_154131-p0mptizj</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sr2369-cornell-university/rav_c/runs/p0mptizj' target=\"_blank\">comic-dream-1</a></strong> to <a href='https://wandb.ai/sr2369-cornell-university/rav_c' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sr2369-cornell-university/rav_c' target=\"_blank\">https://wandb.ai/sr2369-cornell-university/rav_c</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sr2369-cornell-university/rav_c/runs/p0mptizj' target=\"_blank\">https://wandb.ai/sr2369-cornell-university/rav_c/runs/p0mptizj</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wandb\n",
    "from lightning.pytorch.loggers import WandbLogger\n",
    "wandb.init(project=\"rav_c\")\n",
    "wandb_logger = WandbLogger(project=\"rav_c\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rateria/miniconda3/lib/python3.12/site-packages/pytorch_lightning/utilities/parsing.py:208: Attribute 'retriever' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['retriever'])`.\n",
      "/Users/rateria/miniconda3/lib/python3.12/site-packages/pytorch_lightning/utilities/parsing.py:208: Attribute 'ranker' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['ranker'])`.\n",
      "/Users/rateria/miniconda3/lib/python3.12/site-packages/pytorch_lightning/utilities/parsing.py:208: Attribute 'attn' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['attn'])`.\n",
      "/Users/rateria/miniconda3/lib/python3.12/site-packages/pytorch_lightning/utilities/parsing.py:208: Attribute 'classifier' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['classifier'])`.\n"
     ]
    }
   ],
   "source": [
    "model = MyLightningModule(retriever, ranker, attn, classifier, learning_rate=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(max_epochs=1, logger=wandb_logger, accelerator=\"mps\", devices=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rateria/miniconda3/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/Users/rateria/miniconda3/lib/python3.12/site-packages/lightning/pytorch/loggers/wandb.py:396: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "\n",
      "  | Name       | Type               | Params | Mode \n",
      "----------------------------------------------------------\n",
      "0 | retriever  | Retriever          | 109 M  | eval \n",
      "1 | ranker     | Ranker             | 109 M  | eval \n",
      "2 | attn       | TransformerEncoder | 10.3 M | train\n",
      "3 | classifier | Classifier         | 98.8 K | train\n",
      "4 | loss_fn    | CrossEntropyLoss   | 0      | train\n",
      "----------------------------------------------------------\n",
      "10.4 M    Trainable params\n",
      "218 M     Non-trainable params\n",
      "229 M     Total params\n",
      "917.263   Total estimated model params size (MB)\n",
      "56        Modules in train mode\n",
      "465       Modules in eval mode\n",
      "/Users/rateria/miniconda3/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=9` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/59 [00:00<?, ?it/s] classifier after mean torch.Size([500, 768])\n",
      "loss: 1.1196789741516113\n",
      "Epoch 0:   2%|▏         | 1/59 [01:25<1:22:57,  0.01it/s, v_num=tizj]classifier after mean torch.Size([500, 768])\n",
      "loss: 1.4517579078674316\n",
      "Epoch 0:   3%|▎         | 2/59 [02:44<1:18:15,  0.01it/s, v_num=tizj]classifier after mean torch.Size([500, 768])\n",
      "loss: 1.239431381225586\n",
      "Epoch 0:   5%|▌         | 3/59 [04:02<1:15:19,  0.01it/s, v_num=tizj]classifier after mean torch.Size([500, 768])\n",
      "loss: 1.169626235961914\n",
      "Epoch 0:   7%|▋         | 4/59 [05:20<1:13:23,  0.01it/s, v_num=tizj]classifier after mean torch.Size([500, 768])\n",
      "loss: 1.1129121780395508\n",
      "Epoch 0:   8%|▊         | 5/59 [06:37<1:11:33,  0.01it/s, v_num=tizj]classifier after mean torch.Size([500, 768])\n",
      "loss: 1.1032642126083374\n",
      "Epoch 0:  10%|█         | 6/59 [07:55<1:09:58,  0.01it/s, v_num=tizj]classifier after mean torch.Size([500, 768])\n",
      "loss: 1.1057660579681396\n",
      "Epoch 0:  12%|█▏        | 7/59 [09:13<1:08:33,  0.01it/s, v_num=tizj]classifier after mean torch.Size([500, 768])\n",
      "loss: 1.1002302169799805\n",
      "Epoch 0:  14%|█▎        | 8/59 [10:32<1:07:11,  0.01it/s, v_num=tizj]classifier after mean torch.Size([500, 768])\n",
      "loss: 1.0905011892318726\n",
      "Epoch 0:  15%|█▌        | 9/59 [11:49<1:05:41,  0.01it/s, v_num=tizj]classifier after mean torch.Size([500, 768])\n",
      "loss: 1.0669833421707153\n",
      "Epoch 0:  17%|█▋        | 10/59 [13:07<1:04:18,  0.01it/s, v_num=tizj]classifier after mean torch.Size([500, 768])\n",
      "loss: 1.0532273054122925\n",
      "Epoch 0:  19%|█▊        | 11/59 [14:24<1:02:54,  0.01it/s, v_num=tizj]classifier after mean torch.Size([500, 768])\n",
      "loss: 1.0066182613372803\n",
      "Epoch 0:  20%|██        | 12/59 [15:42<1:01:33,  0.01it/s, v_num=tizj]classifier after mean torch.Size([500, 768])\n",
      "loss: 0.9628980755805969\n",
      "Epoch 0:  22%|██▏       | 13/59 [17:01<1:00:14,  0.01it/s, v_num=tizj]classifier after mean torch.Size([500, 768])\n",
      "loss: 0.9063134789466858\n",
      "Epoch 0:  24%|██▎       | 14/59 [18:20<58:56,  0.01it/s, v_num=tizj]  classifier after mean torch.Size([500, 768])\n",
      "loss: 0.928804874420166\n",
      "Epoch 0:  25%|██▌       | 15/59 [19:38<57:36,  0.01it/s, v_num=tizj]classifier after mean torch.Size([500, 768])\n",
      "loss: 0.8636578321456909\n",
      "Epoch 0:  27%|██▋       | 16/59 [20:57<56:18,  0.01it/s, v_num=tizj]classifier after mean torch.Size([500, 768])\n",
      "loss: 0.9188437461853027\n",
      "Epoch 0:  29%|██▉       | 17/59 [22:15<54:59,  0.01it/s, v_num=tizj]classifier after mean torch.Size([500, 768])\n",
      "loss: 1.1019771099090576\n",
      "Epoch 0:  31%|███       | 18/59 [23:34<53:41,  0.01it/s, v_num=tizj]classifier after mean torch.Size([500, 768])\n",
      "loss: 0.9487302303314209\n",
      "Epoch 0:  32%|███▏      | 19/59 [24:53<52:24,  0.01it/s, v_num=tizj]classifier after mean torch.Size([500, 768])\n",
      "loss: 0.8635156154632568\n",
      "Epoch 0:  34%|███▍      | 20/59 [26:12<51:06,  0.01it/s, v_num=tizj]classifier after mean torch.Size([500, 768])\n",
      "loss: 0.9013926982879639\n",
      "Epoch 0:  36%|███▌      | 21/59 [27:32<49:49,  0.01it/s, v_num=tizj]classifier after mean torch.Size([500, 768])\n",
      "loss: 0.9945143461227417\n",
      "Epoch 0:  37%|███▋      | 22/59 [28:50<48:31,  0.01it/s, v_num=tizj]classifier after mean torch.Size([500, 768])\n",
      "loss: 1.011029601097107\n",
      "Epoch 0:  39%|███▉      | 23/59 [30:10<47:13,  0.01it/s, v_num=tizj]classifier after mean torch.Size([500, 768])\n",
      "loss: 0.9294431209564209\n",
      "Epoch 0:  41%|████      | 24/59 [31:28<45:53,  0.01it/s, v_num=tizj]classifier after mean torch.Size([500, 768])\n",
      "loss: 0.8992254734039307\n",
      "Epoch 0:  42%|████▏     | 25/59 [32:47<44:35,  0.01it/s, v_num=tizj]classifier after mean torch.Size([500, 768])\n",
      "loss: 0.8742994666099548\n",
      "Epoch 0:  44%|████▍     | 26/59 [34:09<43:21,  0.01it/s, v_num=tizj]classifier after mean torch.Size([500, 768])\n",
      "loss: 0.893882691860199\n",
      "Epoch 0:  46%|████▌     | 27/59 [35:29<42:03,  0.01it/s, v_num=tizj]classifier after mean torch.Size([500, 768])\n",
      "loss: 0.9128434062004089\n",
      "Epoch 0:  47%|████▋     | 28/59 [36:47<40:44,  0.01it/s, v_num=tizj]classifier after mean torch.Size([500, 768])\n",
      "loss: 0.9056816697120667\n",
      "Epoch 0:  49%|████▉     | 29/59 [38:05<39:24,  0.01it/s, v_num=tizj]classifier after mean torch.Size([500, 768])\n",
      "loss: 0.9048125147819519\n",
      "Epoch 0:  51%|█████     | 30/59 [39:23<38:04,  0.01it/s, v_num=tizj]classifier after mean torch.Size([500, 768])\n",
      "loss: 0.8678386211395264\n",
      "Epoch 0:  53%|█████▎    | 31/59 [40:27<36:32,  0.01it/s, v_num=tizj]classifier after mean torch.Size([500, 768])\n",
      "loss: 0.9091889262199402\n",
      "Epoch 0:  54%|█████▍    | 32/59 [41:08<34:42,  0.01it/s, v_num=tizj]classifier after mean torch.Size([500, 768])\n",
      "loss: 0.857772946357727\n",
      "Epoch 0:  56%|█████▌    | 33/59 [42:23<33:24,  0.01it/s, v_num=tizj]classifier after mean torch.Size([500, 768])\n",
      "loss: 0.8304458260536194\n",
      "Epoch 0:  58%|█████▊    | 34/59 [43:05<31:41,  0.01it/s, v_num=tizj]classifier after mean torch.Size([500, 768])\n",
      "loss: 0.8735454082489014\n",
      "Epoch 0:  59%|█████▉    | 35/59 [43:47<30:01,  0.01it/s, v_num=tizj]classifier after mean torch.Size([500, 768])\n",
      "loss: 0.8676277995109558\n",
      "Epoch 0:  61%|██████    | 36/59 [44:27<28:24,  0.01it/s, v_num=tizj]classifier after mean torch.Size([500, 768])\n",
      "loss: 0.8877264857292175\n",
      "Epoch 0:  63%|██████▎   | 37/59 [45:07<26:49,  0.01it/s, v_num=tizj]classifier after mean torch.Size([500, 768])\n",
      "loss: 0.8422417044639587\n",
      "Epoch 0:  64%|██████▍   | 38/59 [45:47<25:18,  0.01it/s, v_num=tizj]classifier after mean torch.Size([500, 768])\n",
      "loss: 0.9062772989273071\n",
      "Epoch 0:  66%|██████▌   | 39/59 [46:27<23:49,  0.01it/s, v_num=tizj]classifier after mean torch.Size([500, 768])\n",
      "loss: 0.8683753609657288\n",
      "Epoch 0:  68%|██████▊   | 40/59 [47:07<22:23,  0.01it/s, v_num=tizj]classifier after mean torch.Size([500, 768])\n",
      "loss: 0.9169137477874756\n",
      "Epoch 0:  69%|██████▉   | 41/59 [47:48<20:59,  0.01it/s, v_num=tizj]classifier after mean torch.Size([500, 768])\n",
      "loss: 0.9712173342704773\n",
      "Epoch 0:  71%|███████   | 42/59 [48:28<19:37,  0.01it/s, v_num=tizj]classifier after mean torch.Size([500, 768])\n",
      "loss: 0.856048047542572\n",
      "Epoch 0:  73%|███████▎  | 43/59 [49:08<18:17,  0.01it/s, v_num=tizj]classifier after mean torch.Size([500, 768])\n",
      "loss: 0.861708402633667\n",
      "Epoch 0:  75%|███████▍  | 44/59 [49:48<16:58,  0.01it/s, v_num=tizj]classifier after mean torch.Size([500, 768])\n",
      "loss: 0.8729060292243958\n",
      "Epoch 0:  76%|███████▋  | 45/59 [50:28<15:42,  0.01it/s, v_num=tizj]classifier after mean torch.Size([500, 768])\n",
      "loss: 0.9067283272743225\n",
      "Epoch 0:  78%|███████▊  | 46/59 [51:07<14:26,  0.01it/s, v_num=tizj]classifier after mean torch.Size([500, 768])\n",
      "loss: 0.9079218506813049\n",
      "Epoch 0:  80%|███████▉  | 47/59 [51:47<13:13,  0.02it/s, v_num=tizj]classifier after mean torch.Size([500, 768])\n",
      "loss: 0.9441395401954651\n",
      "Epoch 0:  81%|████████▏ | 48/59 [52:26<12:01,  0.02it/s, v_num=tizj]classifier after mean torch.Size([500, 768])\n",
      "loss: 0.8594393730163574\n",
      "Epoch 0:  83%|████████▎ | 49/59 [53:06<10:50,  0.02it/s, v_num=tizj]classifier after mean torch.Size([500, 768])\n",
      "loss: 0.8804619908332825\n",
      "Epoch 0:  85%|████████▍ | 50/59 [53:46<09:40,  0.02it/s, v_num=tizj]classifier after mean torch.Size([500, 768])\n",
      "loss: 0.8643676042556763\n",
      "Epoch 0:  86%|████████▋ | 51/59 [54:25<08:32,  0.02it/s, v_num=tizj]classifier after mean torch.Size([500, 768])\n",
      "loss: 0.8978161811828613\n",
      "Epoch 0:  88%|████████▊ | 52/59 [55:05<07:24,  0.02it/s, v_num=tizj]classifier after mean torch.Size([500, 768])\n",
      "loss: 0.9030112028121948\n",
      "Epoch 0:  90%|████████▉ | 53/59 [55:45<06:18,  0.02it/s, v_num=tizj]classifier after mean torch.Size([500, 768])\n",
      "loss: 0.861696720123291\n",
      "Epoch 0:  92%|█████████▏| 54/59 [56:25<05:13,  0.02it/s, v_num=tizj]classifier after mean torch.Size([500, 768])\n",
      "loss: 0.8463868498802185\n",
      "Epoch 0:  93%|█████████▎| 55/59 [57:05<04:09,  0.02it/s, v_num=tizj]classifier after mean torch.Size([500, 768])\n",
      "loss: 0.9042444825172424\n",
      "Epoch 0:  95%|█████████▍| 56/59 [57:44<03:05,  0.02it/s, v_num=tizj]classifier after mean torch.Size([500, 768])\n",
      "loss: 0.9423452019691467\n",
      "Epoch 0:  97%|█████████▋| 57/59 [58:24<02:02,  0.02it/s, v_num=tizj]classifier after mean torch.Size([500, 768])\n",
      "loss: 0.9221276640892029\n",
      "Epoch 0:  98%|█████████▊| 58/59 [59:04<01:01,  0.02it/s, v_num=tizj]classifier after mean torch.Size([412, 768])\n",
      "loss: 0.9263650178909302\n",
      "Epoch 0: 100%|██████████| 59/59 [59:38<00:00,  0.02it/s, v_num=tizj]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 59/59 [59:40<00:00,  0.02it/s, v_num=tizj]\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, train_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rough Stuff Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.8620)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(torch.tensor([1, 0, 1], dtype=torch.float32), torch.tensor([0, 1, 0], dtype=torch.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.3170299530029297\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define CrossEntropyLoss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Predictions (logits): Shape (N, C)\n",
    "logits = torch.tensor([[2.0, 1.0, 0.1]])  # Batch of size 1, 3 classes\n",
    "\n",
    "# Target labels: Shape (N)\n",
    "targets = torch.tensor([2])  # Class 0 is the correct label\n",
    "\n",
    "# Compute loss\n",
    "loss = criterion(logits, targets)\n",
    "print(f\"Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
